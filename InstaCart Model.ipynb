{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InstaCart Modeling\n",
    "\n",
    "In this notebook, a predictive model for the Kaggle Instacart Challenge (https://www.kaggle.com/c/instacart-market-basket-analysis) is developed. Here, the challenge is, based on 3 million orders of mainly grocery products, to predict the re-ordered products of the next order of users of the Instacart service. Each order consists of none, one or multiple products, and thus the problem is a multi-label classification problem, which for each previously ordered product decides whether or not it will appear in the next order again.\n",
    "\n",
    "The main idea of the notebook is to first generate some very basic (aggregation) features of the data explored in the EDA before. Then, we use some of these features we build a baseline model that does not involve any ML to predict the re-ordered products in an order. This yields an F1-score of 0.329 on the Kaggle public leaderboard (LB), which at the time of submission ranks in the 30th percentile of the competition.\n",
    "\n",
    "Then, we develop a baseline classifier based on LightGBM (https://github.com/Microsoft/LightGBM) and a very basic set of features. While the very initial version has a very bad scoring of ~0.2, adding some more meaningful features boosts performance to 0.3805. Incorporating per-order thresholds increases the F1-score on the LB to 0.386, and with parameter tuning the LightGBM model we are able to further increase the score to 0.397. At the time of submission, the solution ranked in the 95th percentile of the competition (Rank 120 of ~2,500 entries).\n",
    "\n",
    "The final model then considers a few additional features, as well as stacking multiple classifiers and merging their predicted probabilities before calculating the per-order threshold. The final ranking of the submission is in the 91st percentile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Import libraries\n",
    "#\n",
    "######################################################\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "\n",
    "import collections\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Read in data\n",
    "#\n",
    "######################################################\n",
    "\n",
    "orders = pd.read_csv('orders.csv')\n",
    "prior = pd.read_csv('order_products__prior.csv')\n",
    "train = pd.read_csv('order_products__train.csv')\n",
    "aisles = pd.read_csv('aisles.csv')\n",
    "departments = pd.read_csv('departments.csv')\n",
    "products = pd.read_csv('products.csv')\n",
    "\n",
    "# merge prior with order information\n",
    "prior = pd.merge(prior, orders, on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Prediction (without any Machine Learning)\n",
    "\n",
    "Here, the basic idea is to simply look at (i) the average order size of a customer and (ii) the products that that customer re-ordered most often. Then, starting from the highest re-order ratio, add products until the average order size is hit. This model results in a score of 0.329 on the Kaggle LB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = orders[orders.eval_set == 'test']\n",
    "sample_sub = pd.DataFrame(columns=['order_id', 'products'])\n",
    "sample_sub['order_id'] = test['order_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this takes some time...\n",
    "def get_products(order_id):\n",
    "    prods_predicted = []\n",
    "    uid = test[test['order_id'] == order_id]['user_id'].iloc[0]\n",
    "    cur_prods = prods[prods['user_id'] == uid]\n",
    "    avg_size = int(round(users[users['user_id'] == uid]['u_average_order_size'].iloc[0]))\n",
    "    \n",
    "    for x in range(0,avg_size):\n",
    "        prods_predicted.append(cur_prods['product_id'].iloc[x])\n",
    "    return prods_predicted\n",
    "\n",
    "\n",
    "sample_sub['products'] = sample_sub['order_id'].apply(lambda x: get_products(x)).apply(lambda x: \" \".join(str(y) for y in x))\n",
    "sample_sub.to_csv('sample_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Model - Requires Basic Feature Engineering - Aggregated Stats\n",
    "\n",
    "For our very first model, we will calculate a few basic new features. These features are mainly aggregated stats such as sums, averages, standard deviations, counts, etc. For instance, the mean of the *'reordered'* column for a product reflects the per-product reorder ratio.\n",
    "\n",
    "There are in general three different kinds of features that we calculate now:\n",
    "\n",
    "* User Statistics: indicated by prefix *u_*\n",
    "* Product Statistics: indicated by prefix *p_*\n",
    "* User x Product statistics: indicated by prefix *u_*p_\n",
    "\n",
    "## User Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create dataframe for user stats\n",
    "users = pd.DataFrame(prior['user_id'].unique(), columns=['user_id'])\n",
    "\n",
    "# calculate stats based on prior data\n",
    "user_stats = prior.groupby(['user_id','order_id']).size()\n",
    "gb_user_id = user_stats.groupby('user_id')\n",
    "prior_user_id = prior.groupby('user_id')\n",
    "std_dev = gb_user_id.std().reset_index()\n",
    "user_hist = gb_user_id.mean().reset_index()\n",
    "order_size = prior_user_id.size().reset_index()\n",
    "order_count = prior_user_id['order_number'].max().reset_index()\n",
    "user_avgs = prior_user_id.mean().reset_index()\n",
    "user_avgs = user_avgs[['user_id', 'reordered','order_dow', 'order_hour_of_day', 'days_since_prior_order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge user frame with new features\n",
    "users = pd.merge(users, std_dev, on='user_id', how='left')\n",
    "users = pd.merge(users, user_hist, on='user_id', how='left')\n",
    "users = pd.merge(users, order_size , on='user_id', how='left')\n",
    "users = pd.merge(users, order_count , on='user_id', how='left')\n",
    "users = pd.merge(users, user_avgs, on = 'user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename features to more meaningful names\n",
    "users.columns = ['user_id', 'u_std_dev_order_size', 'u_average_order_size', 'u_tot_ordered_products', \n",
    "                 'u_order_count', 'u_avg_reorder_ratio', 'u_avg_order_dow', 'u_avg_order_hod', 'u_avg_dspo']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# make a frame for product stats\n",
    "prod_stats = products.copy()\n",
    "\n",
    "# calculate stats based on prior data\n",
    "prior_by_prod = prior.groupby('product_id')\n",
    "prod_avgs = prior_by_prod.mean().reset_index()\n",
    "prod_count = prior[prior['reordered'] == 1].groupby('product_id').count().reset_index()\n",
    "prod_size = prior_by_prod.size().reset_index()\n",
    "prod_avgs = prod_avgs[['product_id', 'add_to_cart_order', 'reordered', 'order_dow', 'order_number', \n",
    "                       'order_hour_of_day', 'days_since_prior_order']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rename features to more meaningful names\n",
    "prod_avgs.columns = ['product_id', 'p_avg_add_to_cart', 'p_avg_reorder_ratio', 'p_avg_order_dow', 'p_avg_ord_num', \n",
    "                     'p_avg_order_hod', 'p_avg_dspo']\n",
    "prod_count = prod_count[['product_id', 'reordered']]\n",
    "prod_count.columns = ['product_id', 'p_count_reorders']\n",
    "prod_size.columns = ['product_id', 'p_total_orders']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# merge frames\n",
    "prod_stats = pd.merge(prod_stats, prod_avgs, on='product_id', how='left')\n",
    "prod_stats = pd.merge(prod_stats, prod_count, on='product_id', how='left')\n",
    "prod_stats = pd.merge(prod_stats, prod_size, on='product_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product-to-User Aggregated Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# amount of times a particular user ordered a particular item\n",
    "prods = prior.groupby('user_id')['product_id'].value_counts().to_frame('times_ordered').reset_index()\n",
    "# merge with some of the user stats\n",
    "prods = pd.merge(prods, users[['user_id','u_order_count','u_average_order_size']], how='left', on='user_id' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create new frame for prod_x_user stats\n",
    "\n",
    "prods_by_users = pd.DataFrame()\n",
    "prods_by_users[['user_id','product_id']] = prods[['user_id','product_id']]\n",
    "prods_by_users = pd.merge(prods_by_users, prod_stats[prod_stats.columns.difference(['product_name','aisle_id','department_id'])],\n",
    "                          on='product_id', how='left')\n",
    "\n",
    "by_usr = prior.groupby(['user_id','product_id']).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prods_by_users = pd.merge(prods_by_users, by_usr, on=['user_id','product_id'], how='left')\n",
    "#rename columns\n",
    "prods_by_users.columns = ['user_id', 'product_id', 'p_avg_add_to_cart',\n",
    "       'p_avg_dspo', 'p_avg_ord_num', 'p_avg_order_dow', 'p_avg_order_hod',\n",
    "       'p_avg_reorder_ratio', 'p_count_reorders', 'p_total_orders',\n",
    "       'u_p_avg_order_id', 'u_p_avg_add_to_cart_order', 'u_p_avg_reordered', 'u_p_avg_order_number',\n",
    "       'u_p_avg_order_dow', 'u_p_avg_order_hour_of_day', 'u_p_avg_days_since_prior_order']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# some more features\n",
    "\n",
    "prods_by_users['u_p_diff_cart_order'] = prods_by_users['p_avg_add_to_cart'] - prods_by_users['u_p_avg_add_to_cart_order']\n",
    "prods_by_users['u_p_diff_days_since_prior'] = prods_by_users['p_avg_dspo'] - prods_by_users['u_p_avg_days_since_prior_order']\n",
    "prods_by_users['u_p_diff_order_dow'] = prods_by_users['p_avg_order_dow'] - prods_by_users['u_p_avg_order_dow']\n",
    "prods_by_users['u_p_diff_order_hod'] = prods_by_users['p_avg_order_hod'] - prods_by_users['u_p_avg_order_hour_of_day']\n",
    "prods_by_users['u_p_diff_reorder_ratio'] = prods_by_users['p_avg_reorder_ratio'] - prods_by_users['u_p_avg_reordered']\n",
    "\n",
    "prods_by_users['u_p_order_count'] = prods['times_ordered']\n",
    "prods_by_users['u_p_order_ratio'] = prods['times_ordered'] / prods ['u_order_count']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Predictor (simple classifier)\n",
    "\n",
    "Now, we will take our model to a next step by actually involving ML algorithms in order to improve the scoring. We'll start with a rather simple ML classifier. The task at hand is multi-label classification. The approach will be: Run a multi-label classifier that yields probabilities for re-ordering, and then find a cut-off in these probabilities to determine at which point a product is projected to be re-ordered in the next order."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what we want to predict. In the test set, we see that we are simply given an *order_id*, together with a *user_id* and several features (*order_number, order_dow, order_hour_of_day, days_since_prior_order*), and we need to predict which products the customer will re-order. For that, we first need to know which products the customer has ordered before (all other products can not be re-ordered).\n",
    "\n",
    "Once we have a list of all products a user has ever ordered before (we can take this from the *prior* dataset), in the next step, we need to yield an estimate of whether or not each product will be re-ordered. Afterwards, we can take the predicted value to derive the set of products we expect for a particular user. \n",
    "\n",
    "For each product, we determine a probability of being in the next basket (i.e., a value $p$ in $[0,1]$), and then we tune a parameter $p_b$ that acts as a threshold basket probability, i.e., all items with a probability $p > p_b$ are included into the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Prepare train data, merge with previously calculated\n",
    "# stats.\n",
    "#\n",
    "######################################################\n",
    "\n",
    "train = orders[orders.eval_set == 'train']\n",
    "train_orders = pd.read_csv('order_products__train.csv')\n",
    "train = pd.merge(train, prods, on='user_id', how='left')\n",
    "train = pd.merge(train, train_orders, on=['order_id','product_id'], how='left')\n",
    "train = pd.merge(train, prods_by_users, on=['user_id', 'product_id'], how='left')\n",
    "train = pd.merge(train, products[['product_id','aisle_id','department_id']], on='product_id', how='left')\n",
    "train = pd.merge(train, users[users.columns.difference(['u_average_order_size', 'u_order_count'])], on='user_id', how='left')\n",
    "# each user has set of products he has ever ordered before.\n",
    "# out of this set, only a fraction may be present in the train order,\n",
    "# which means that the user has also not reordered a lot of products\n",
    "# --> need to set all products not in the train order to 0\n",
    "train['reordered'] = train['reordered'].fillna(0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Define features and parameters for baseline model.\n",
    "# Note that we are using LightGBM as the classifier.\n",
    "# LightGBM typically operates much fast than a random\n",
    "# forest and has shown to achieve performance better\n",
    "# or close to XGBoost.\n",
    "#\n",
    "######################################################\n",
    "\n",
    "#very simple feature set, only use a couple of product related stats other than features already provided in the data\n",
    "features = ['order_dow', 'order_hour_of_day', 'days_since_prior_order','p_avg_reorder_ratio', \n",
    "            'p_count_reorders', 'p_total_orders', 'aisle_id', 'department_id']\n",
    "\n",
    "#parameters for LightGBM - need to tune these later\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 70,\n",
    "    'min_data_in_leaf': 25,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Train LightGBM model\n",
    "#\n",
    "######################################################\n",
    "\n",
    "# prepare train set\n",
    "train_lgb = lgb.Dataset(train[features], train['reordered'])\n",
    "res = lgb.train(params, train_lgb, 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Prepare test data\n",
    "#\n",
    "######################################################\n",
    "\n",
    "test = orders[orders.eval_set == 'test']\n",
    "test = pd.merge(test, prods, on='user_id', how='left')\n",
    "test = pd.merge(test, prods_by_users, on=['user_id', 'product_id'], how='left')\n",
    "test = pd.merge(test, products[['product_id','aisle_id','department_id']], on='product_id', how='left')\n",
    "test = pd.merge(test, users[users.columns.difference(['u_average_order_size', 'u_order_count'])], on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for testing purposes, we don't want to mess with our test set (reusability), thus make a copy\n",
    "test_cpy = test.copy()\n",
    "test_cpy['preds'] = res.predict(test_cpy[features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to determine the added products: Threshold approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cpy = test_cpy[['order_id', 'user_id','product_id','preds']]\n",
    "\n",
    "######################################################\n",
    "#\n",
    "# Include product into set if probability is > 0.21 \n",
    "# - this value was tested to yield best results, and is also ~1/2 of the F1 score leading the LB.\n",
    "# This has been shown to be a good approximation of the optimal threshold, see: https://arxiv.org/abs/1402.1892\n",
    "#\n",
    "######################################################\n",
    "\n",
    "test_cpy['included'] = test_cpy['preds'].apply(lambda x: 1 if x > 0.21 else 0)\n",
    "test_cpy = test_cpy[test_cpy.included == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_products(order_id):\n",
    "    subset = test_cpy[test_cpy['order_id'] == order_id]\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        return 'None'\n",
    "    else:\n",
    "        prods_predicted = []\n",
    "        prods_predicted.extend(subset['product_id'])\n",
    "        return prods_predicted\n",
    "\n",
    "\n",
    "sample_sub = pd.DataFrame(columns=['order_id', 'products'])\n",
    "sample_sub['order_id'] = test['order_id'].unique()\n",
    "sample_sub['products'] = sample_sub['order_id'].apply(lambda x: get_products(x)).apply(lambda x: (\" \".join(str(y) for y in x) if x != 'None' else 'None'))\n",
    "\n",
    "sample_sub = sample_sub.sort_values(by='order_id')\n",
    "sample_sub.to_csv('sample_submission_baseline_thresh.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives a result of just 0.20 on the Kaggle LB. However, this is to be expected, since there are just very few meaningful features that would help to obtain a good score - in other words, the probabilities of inclusion are too similar for most products and the information retained in the baseline (without ML) is more helpful here. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving the Baseline Classifier\n",
    "\n",
    "We now want to improve the performance of the baseline classifier by adding meaningful features. To evaluate whether or not a feature gives us some improvement, we will use cross-validation. We should not use random allocation of these sets in order to avoid overfitting to particular users. Rather, train and validation should not have overlapping users, and subsequently, the cross-validation folds used in the train set should respect the same property"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_lgb = lgb.Dataset(train[features], train['reordered'], categorical_feature=['aisle_id', 'department_id',\n",
    "                                                                                  'order_dow','order_hour_of_day',\n",
    "                                                                                  'days_since_prior_order'])\n",
    "\n",
    "#cast LGB to sklearn (better cross validation functionality)\n",
    "clf = lgb.LGBMClassifier(\n",
    "    task = 'train',\n",
    "    boosting_type = 'dart',\n",
    "    objective = 'binary',\n",
    "    metric = {'binary_logloss'},\n",
    "    num_leaves = 70,\n",
    "    min_data_in_leaf = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define custom folds based on unique user_ids\n",
    "custom_folds = GroupKFold(n_splits=5).split(X=train[train.columns.difference(['reordered'])], \n",
    "                                            y=train['reordered'], \n",
    "                                            groups=train['user_id'])\n",
    "\n",
    "# Compute cross validation score  \n",
    "cross_val_score(clf, \n",
    "                X=train[features], \n",
    "                y=train['reordered'],\n",
    "                scoring='neg_log_loss',\n",
    "                cv=custom_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CV Log-loss is currently ~0.393 - Now we can add additional features to check on how to improve it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all of the following features contribute to improving the score, i.e., reducing log-loss\n",
    "features = [ \n",
    "            # general features\n",
    "            'order_dow', 'order_hour_of_day', 'days_since_prior_order', 'aisle_id', 'department_id',\n",
    "            # user related features\n",
    "            'u_tot_ordered_products', 'u_order_count', 'u_avg_reorder_ratio', \n",
    "            # product-related features\n",
    "            'p_avg_reorder_ratio', 'p_count_reorders', 'p_total_orders', 'p_avg_add_to_cart',\n",
    "            # user-product-features\n",
    "            'u_p_avg_reordered', 'u_p_avg_order_number', 'u_p_order_ratio'\n",
    "           ]\n",
    "\n",
    "train_lgb = lgb.Dataset(train[features], train['reordered'], \n",
    "                        categorical_feature=['aisle_id', 'department_id','order_dow','order_hour_of_day',\n",
    "                                             'days_since_prior_order'])\n",
    "\n",
    "# Define custom folds\n",
    "custom_folds = GroupKFold(n_splits=5).split(X=train[train.columns.difference(['reordered'])], \n",
    "                                            y=train['reordered'], \n",
    "                                            groups=train['user_id'])\n",
    "\n",
    "cross_val_score(clf, \n",
    "                X=train[features], \n",
    "                y=train['reordered'],\n",
    "                scoring='neg_log_loss',\n",
    "                cv=custom_folds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, log-loss is below 0.37. Let's try to use these features as our next baseline and train the model on the entire train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "res = lgb.train(params, train_lgb, 90)\n",
    "\n",
    "# let's see which features were most important\n",
    "lgb.plot_importance(res, figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# repeat as previously\n",
    "test_cpy = test.copy()\n",
    "test_cpy['preds'] = res.predict(test_cpy[features])\n",
    "test_cpy = test_cpy[['order_id', 'user_id','product_id','u_average_order_size','preds']]\n",
    "test_cpy['included'] = test_cpy['preds'].apply(lambda x: 1 if x > 0.21 else 0)\n",
    "test_cpy = test_cpy[test_cpy.included == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# this takes some time...\n",
    "def get_products(order_id):\n",
    "    subset = test_cpy[test_cpy['order_id'] == order_id]\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        return 'None'\n",
    "    else:\n",
    "        prods_predicted = []\n",
    "        prods_predicted.extend(subset['product_id'])\n",
    "        return prods_predicted\n",
    "\n",
    "\n",
    "sample_sub = pd.DataFrame(columns=['order_id', 'products'])\n",
    "sample_sub['order_id'] = test['order_id'].unique()\n",
    "sample_sub['products'] = sample_sub['order_id'].apply(lambda x: get_products(x)).apply(lambda x: (\" \".join(str(y) for y in x) if x != 'None' else 'None'))\n",
    "\n",
    "sample_sub = sample_sub.sort_values(by='order_id')\n",
    "sample_sub.to_csv('sample_submission_agg_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scores 0.371 on the LB, which is a huge improvement, not only towards the baseline lightGBM classifier, but also to the baseline without ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced feature engineering\n",
    "\n",
    "Previously, our features are very basic statistics that can be derived by pandas aggregation functionalities. We will now introduce additional features, which will often be derived from existing features in order to determine better which product is valuable to which user, and thus more likely to be re-ordered. Examples for such features are:\n",
    "\n",
    "* Was the product contained in the last order? Was it in the second last order? Was it in the 3rd last order? All users have at least three recorded orders in the prior set, so we can check this. The assumption is that more recent orders tell us more about what items a customer will reorder.\n",
    "* How does the current order differ from previous ones (hour of day, day of week, days since prior order difference)?\n",
    "* How much time has passed since the user ordered the product the last time?\n",
    "* How much time has passed since the user ordered the product the first time?\n",
    "* etc.\n",
    "\n",
    "Additionally, we will have some more rather basic features (like the number of distinct products a user has ordered, which may hint at how consistent he/she is)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# All of the following features reduce logloss. Note \n",
    "# that many more features have been tried, but are not\n",
    "# included as they did not help to improve logloss,\n",
    "# and sometimes worsened it\n",
    "#\n",
    "######################################################\n",
    "train['ratio_dspo'] = train['days_since_prior_order'] / train['u_p_avg_days_since_prior_order']\n",
    "train['diff_order_dow'] = train['order_dow'] - train['u_p_avg_order_dow']\n",
    "train['diff_order_hod'] = train['order_hour_of_day'] - train['u_p_avg_order_hour_of_day']\n",
    "train['max_dspo_order'] = train['days_since_prior_order'].apply(lambda x: 1 if x==30 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# difference in dspo\n",
    "orders['o_dspo_diff'] = orders['days_since_prior_order'].diff().fillna(orders['days_since_prior_order'])\n",
    "\n",
    "# lifetime of a user in the system, the cumulative sum of days since prior order\n",
    "orders['o_user_lifetime'] = orders.groupby('user_id').cumsum()['days_since_prior_order']\n",
    "\n",
    "# number of distinct products ordered by the user\n",
    "dist_prods =  prior.groupby('user_id')['product_id'].nunique().reset_index()\n",
    "dist_prods.columns = ['user_id', 'u_dist_prods']\n",
    "\n",
    "# merge dfs\n",
    "users = pd.merge(users, dist_prods, on='user_id', how='left')\n",
    "train = pd.merge(train, orders[['order_id','o_dspo_diff', 'o_user_lifetime']], on='order_id', how='left')\n",
    "train = pd.merge(train, users[['user_id','u_dist_prods']], on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get max order number \n",
    "tot_orders = users[['user_id','u_order_count']]\n",
    "orders = pd.merge(orders, tot_orders, on='user_id', how='left')\n",
    "prior = pd.merge(prior, orders[['order_id','u_order_count']], on='order_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# list all products that were in the last order\n",
    "last_order_products = prior[prior['order_number'] == prior['u_order_count']].groupby(['user_id'])['product_id'].aggregate(lambda x: list(x)).reset_index()\n",
    "last_order_products.columns = ['user_id','last_order_prods']\n",
    "train = pd.merge(train, last_order_products, on='user_id', how='left')\n",
    "# for each product in the train set (i.e., each product the user has ever ordered), check whether it was in the last order\n",
    "train['u_p_in_last_order'] = train.apply(lambda x: 1 if x['product_id'] in x['last_order_prods'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# repeat above steps also for 2nd, and 3rd last order \n",
    "# - each user has at least 3 orders recorded, so we can safely go back that far\n",
    "two_orders_ago = prior[prior['order_number'] == (prior['u_order_count']-1)].groupby(['user_id'])['product_id'].aggregate(lambda x: list(x)).reset_index()\n",
    "three_orders_ago = prior[prior['order_number'] == (prior['u_order_count']-2)].groupby(['user_id'])['product_id'].aggregate(lambda x: list(x)).reset_index()\n",
    "two_orders_ago.columns = ['user_id','2nd_last_order_prods']\n",
    "three_orders_ago.columns = ['user_id','3rd_last_order_prods']\n",
    "train = pd.merge(train, two_orders_ago, on='user_id', how='left')\n",
    "train = pd.merge(train, three_orders_ago, on='user_id', how='left')\n",
    "train['u_p_in_2nd_last_order'] = train.apply(lambda x: 1 if x['product_id'] in x['2nd_last_order_prods'] else 0, axis=1)\n",
    "train['u_p_in_3rd_last_order'] = train.apply(lambda x: 1 if x['product_id'] in x['3rd_last_order_prods'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# min/max aggregations - this takes a long time, execute with care!\n",
    "u_p_max = prior.groupby(['user_id','product_id']).max().reset_index()\n",
    "u_p_min = prior.groupby(['user_id','product_id']).min().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u_p_max.columns = ['user_id', 'product_id', 'u_p_max_order_id', 'u_p_max_add_to_cart_order', 'u_p_max_reordered',\n",
    "                   'u_p_max_eval_set', 'u_p_max_order_number', 'u_p_max_order_dow', 'u_p_max_order_hour_of_day', \n",
    "                   'u_p_max_days_since_prior_order', 'u_p_max_order_count']\n",
    "u_p_min.columns = ['user_id', 'product_id', 'u_p_min_order_id', 'u_p_min_add_to_cart_order', 'u_p_min_reordered',\n",
    "                   'u_p_min_eval_set', 'u_p_min_order_number', 'u_p_min_order_dow', 'u_p_min_order_hour_of_day', \n",
    "                   'u_p_min_days_since_prior_order', 'u_p_min_order_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.merge(train, u_p_max[['user_id', 'product_id', 'u_p_max_order_id', 'u_p_max_add_to_cart_order', 'u_p_max_reordered',\n",
    "                   'u_p_max_order_number', 'u_p_max_order_dow', 'u_p_max_order_hour_of_day', \n",
    "                   'u_p_max_days_since_prior_order', 'u_p_max_order_count']],\n",
    "                 on=['user_id', 'product_id'], how='left')\n",
    "train = pd.merge(train, u_p_min[['user_id', 'product_id', 'u_p_min_order_id', 'u_p_min_add_to_cart_order', 'u_p_min_reordered',\n",
    "                   'u_p_min_order_number', 'u_p_min_order_dow', 'u_p_min_order_hour_of_day', \n",
    "                   'u_p_min_days_since_prior_order', 'u_p_min_order_count']],\n",
    "                 on=['user_id', 'product_id'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# determine when the user has first bought the product, and when he has last ordered it\n",
    "train['u_p_time_since_last_buy'] = train['order_number'] - train['u_p_max_order_number']\n",
    "train['u_p_time_since_first_buy'] = train['order_number'] - train['u_p_min_order_number']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to test whether our features are actually working or not! Note that the below list of features is rather small compared to the features we have created in the course of this notebook. All features that are not listed below do not yield any improvement on the CV score and were thus not included in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#all of the following features contribute to decreasing log loss\n",
    " \n",
    "features = [ \n",
    "            # BASIC general features\n",
    "            'order_dow', 'order_hour_of_day', 'days_since_prior_order', 'aisle_id', 'department_id',\n",
    "            # BASIC user related features\n",
    "            'u_tot_ordered_products', 'u_order_count', 'u_avg_reorder_ratio', 'u_average_order_size',\n",
    "            'u_dist_prods',\n",
    "            # BASIC product-related features\n",
    "            'p_avg_reorder_ratio', 'p_count_reorders', 'p_total_orders', 'p_avg_add_to_cart',\n",
    "            # BASIC user-product-features\n",
    "            'u_p_avg_reordered', 'u_p_avg_order_number', 'u_p_order_ratio', 'u_p_max_order_number',\n",
    "            'u_p_min_order_number',           \n",
    "            # ratios\n",
    "            'ratio_dspo', \n",
    "            # differences\n",
    "            'diff_order_dow', 'diff_order_hod', 'o_dspo_diff', 'u_p_time_since_last_buy', \n",
    "            'u_p_time_since_first_buy',\n",
    "            # categoricals\n",
    "            'max_dspo_order',  'u_p_in_last_order', 'u_p_in_2nd_last_order', 'u_p_in_3rd_last_order', \n",
    "           ]\n",
    "\n",
    "\n",
    "train_lgb = lgb.Dataset(train[features], train['reordered'])\n",
    "\n",
    "# Define custom folds\n",
    "custom_folds = GroupKFold(n_splits=5).split(X=train[train.columns.difference(['reordered'])], \n",
    "                                            y=train['reordered'], \n",
    "                                            groups=train['user_id'])\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    task = 'train',\n",
    "    boosting_type = 'dart',\n",
    "    objective = 'binary',\n",
    "    metric = {'binary_logloss'},\n",
    "    num_leaves = 70,\n",
    "    min_data_in_leaf = 25)\n",
    "\n",
    "cross_val_score(clf, \n",
    "                X=train[features], \n",
    "                y=train['reordered'],\n",
    "                scoring='neg_log_loss',\n",
    "                cv=custom_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "array([-0.36546325, -0.3658442 , -0.36593602, -0.36538184, -0.36470168]) # for outputcheck\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tiny bit improvement in the score! Log-loss @ 0.365 - now we will mirror these features to the test set, and then subsequently train the model again to check the score on the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# mirror features in test set\n",
    "test['ratio_dspo'] = test['days_since_prior_order'] / test['u_p_avg_days_since_prior_order']\n",
    "test['diff_order_dow'] = test['order_dow'] - test['u_p_avg_order_dow']\n",
    "test['diff_order_hod'] = test['order_hour_of_day'] - test['u_p_avg_order_hour_of_day']\n",
    "test['max_dspo_order'] = test['days_since_prior_order'].apply(lambda x: 1 if x==30 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, orders[['order_id','o_dspo_diff', 'o_user_lifetime']], on='order_id', how='left')\n",
    "test = pd.merge(test, users[['user_id','u_dist_prods']], on='user_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, u_p_max[['user_id', 'product_id', 'u_p_max_order_id', 'u_p_max_add_to_cart_order', 'u_p_max_reordered',\n",
    "                   'u_p_max_order_number', 'u_p_max_order_dow', 'u_p_max_order_hour_of_day', \n",
    "                   'u_p_max_days_since_prior_order', 'u_p_max_order_count']],\n",
    "                 on=['user_id', 'product_id'], how='left')\n",
    "test = pd.merge(test, u_p_min[['user_id', 'product_id', 'u_p_min_order_id', 'u_p_min_add_to_cart_order', 'u_p_min_reordered',\n",
    "                   'u_p_min_order_number', 'u_p_min_order_dow', 'u_p_min_order_hour_of_day', \n",
    "                   'u_p_min_days_since_prior_order', 'u_p_min_order_count']],\n",
    "                 on=['user_id', 'product_id'], how='left')\n",
    "test['u_p_time_since_last_buy'] = test['order_number'] - test['u_p_max_order_number']\n",
    "test['u_p_time_since_first_buy'] = test['order_number'] - test['u_p_min_order_number']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, last_order_products, on='user_id', how='left')\n",
    "test['u_p_in_last_order'] = test.apply(lambda x: 1 if x['product_id'] in x['last_order_prods'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.merge(test, two_orders_ago, on='user_id', how='left')\n",
    "test = pd.merge(test, three_orders_ago, on='user_id', how='left')\n",
    "test['u_p_in_2nd_last_order'] = test.apply(lambda x: 1 if x['product_id'] in x['2nd_last_order_prods'] else 0, axis=1)\n",
    "test['u_p_in_3rd_last_order'] = test.apply(lambda x: 1 if x['product_id'] in x['3rd_last_order_prods'] else 0, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model and submit scores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Note: LightGBM params are an initial guess - we will tune them later on\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'dart',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 70,\n",
    "    'min_data_in_leaf': 25,\n",
    "}\n",
    "\n",
    "res = lgb.train(params, train_lgb, 90)\n",
    "lgb.plot_importance(res, figsize=(12,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cpy = test.copy()\n",
    "test_cpy['preds'] = res.predict(test_cpy[features])\n",
    "test_cpy = test_cpy[['order_id', 'user_id','product_id','u_average_order_size','preds']]\n",
    "test_cpy['included'] = test_cpy['preds'].apply(lambda x: 1 if x > 0.21 else 0)\n",
    "test_cpy = test_cpy[test_cpy.included == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_products(order_id):\n",
    "    subset = test_cpy[test_cpy['order_id'] == order_id]\n",
    "    \n",
    "    if len(subset) == 0:\n",
    "        return 'None'\n",
    "    else:\n",
    "        prods_predicted = []\n",
    "        prods_predicted.extend(subset['product_id'])\n",
    "        return prods_predicted\n",
    "\n",
    "\n",
    "sample_sub = pd.DataFrame(columns=['order_id', 'products'])\n",
    "sample_sub['order_id'] = test['order_id'].unique()\n",
    "sample_sub['products'] = sample_sub['order_id'].apply(lambda x: get_products(x)).apply(lambda x: (\" \".join(str(y) for y in x) if x != 'None' else 'None'))\n",
    "\n",
    "sample_sub = sample_sub.sort_values(by='order_id')\n",
    "sample_sub.to_csv('sample_submission_agg_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Save current dfs to disk so that we do not have to\n",
    "# re-calculate features again.\n",
    "# Storing in a binary format (here: hdf) prevents\n",
    "# conversion of float to decimals, and thus keeps the\n",
    "# original data.\n",
    "#\n",
    "######################################################\n",
    "\n",
    "train.to_hdf('train.hdf','train_data')\n",
    "test.to_hdf('test.hdf', 'test_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This solutions boosts the leaderboard score up to 0.3805. Again, a considerable boost. The process so far was rather simple and consisted purely of feature engineering. Let's check out something more interesting.\n",
    "\n",
    "# Improving Performance with expected F1 score and handling None\n",
    "\n",
    "So far, our approach was built on the assumption that there is one general threshold that is fitting well across all orders from all customers. Of course, in reality, users are very different from each other in their shopping behaviour. Some may be rather consistent, while others can have pretty wide-spread product orders with a high variance in their orders.\n",
    "\n",
    "Therefore, it would be better to obtain *order-dependant* thresholds. There are a couple of ways to achieve this. We could, for instance, predict the average basket size of a user, and then select the products with the highest probability to go into the basket. \n",
    "\n",
    "This would require a separate classifier, which, based on features like average user basket size, variance in basket sizes, basket sizes in dependance of hour of day or day of week, etc., could try to predict a proper basket size.\n",
    "\n",
    "Another alternative is to calculate the per-order threshold as a function of the expected F1 score. For details, see the paper: \"Ye, N., Chai, K., Lee, W., and Chieu, H.  Optimizing F-measures: A Tale of Two Approaches.\", in Proceedings of the International Conference on Machine Learning, 2012.\n",
    "Basically, what this script does is to look at the probabilities obtained by our classifier and then finds a per-order threshold based on these probabilities. The threshold $t$ is found by looking at which threshold maximizes the expected F1 score for the set of probabilities. Finally, the script returns the basket size (k).\n",
    "\n",
    "Also, we will handle the case in which an order is not containing any reordered product. If this is the case, we need to predict an explicit 'None'. Our approach here is to also encode this scenario as a probability. In particular: $p_i(None) = 1 - p_i(prod_1) * p_i(prod_2)* ... * p_i(prod_j)$ for each user $i$ with $j$ product candidates. Then, if $p_i(None) > t$, it is included into the prediction, if not, it is not. Note that this can lead to situations, in which both 'None' and (a set of) products can be ultimately predicted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from f1_maximizer import F1Optimizer as f1opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cpy = test.copy()\n",
    "test_cpy['preds'] = res.predict(test_cpy[features])\n",
    "test_cpy = test_cpy[['order_id', 'user_id','product_id','preds']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_cpy = test_cpy.sort_values(by='preds', ascending=False)\n",
    "test_cpy['prod_prob'] = zip(test_cpy['product_id'], test_cpy['preds'])\n",
    "prod_probs_by_order = test_cpy.groupby('order_id')['prod_prob'].aggregate(lambda x: list(x)).reset_index()\n",
    "prod_probs_by_order.columns = ['order_id','prod_probs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#this takes a long time, but does the job - @TODO: get rid of for loop\n",
    "final_pred = {}\n",
    "for order_id in prod_probs_by_order['order_id']:\n",
    "    pred_prods = []\n",
    "    unzipped = zip(*prod_probs_by_order[prod_probs_by_order['order_id'] == order_id]['prod_probs'].values[0])\n",
    "    k, none_in, exp = f1opt.maximize_expectation(unzipped[1])       \n",
    "    pred_prods.extend(unzipped[0][:k])\n",
    "    if (none_in) or (k == 0):\n",
    "        pred_prods.append('None')  \n",
    "    final_pred[order_id] = pred_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub = pd.DataFrame(columns=['order_id', 'products'])\n",
    "f_pred = collections.OrderedDict(sorted(final_pred.items()))\n",
    "sample_sub['order_id'] = f_pred.keys()\n",
    "sample_sub['products'] = f_pred.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub['products'] = sample_sub['products'].apply(lambda x: (\" \".join(str(y) for y in x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_sub.to_csv('sample_submission_agg_features_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This further increases the model performance to a leaderboard score of 0.386!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Performance by Parameter Tuning\n",
    "\n",
    "Next, we further try to increase the performance by parameter tuning. Here, we have to consider the basic trade-off of model complexity: The more complex a model is, the more likely it is to overfit on the training data. Hence, cross validation is extremely important here.\n",
    "\n",
    "Below is a final definition of the parameters we will use. Commented beyond that are parameter settings that have been tried out in the process. The most gain is achived with, in decreasing importance:\n",
    "\n",
    "* learning_rate: tuning this parameter yields a huge performance boost on the local log-loss CV score.\n",
    "* num_leaves\n",
    "* boosting_type: dart yields a .01 improvement over gbdt.\n",
    "\n",
    "We observe that the local cv score has *drastically* decreased to ~.245. Parameter tuning boosts our score to 0.397."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = [ \n",
    "            # BASIC general features\n",
    "            'order_dow', 'order_hour_of_day', 'days_since_prior_order', 'aisle_id', 'department_id',\n",
    "            # BASIC user related features\n",
    "            'u_tot_ordered_products', 'u_order_count', 'u_avg_reorder_ratio', 'u_average_order_size',\n",
    "            'u_dist_prods',\n",
    "            # BASIC product-related features\n",
    "            'p_avg_reorder_ratio', 'p_count_reorders', 'p_total_orders', 'p_avg_add_to_cart',\n",
    "            # BASIC user-product-features\n",
    "            'u_p_avg_reordered', 'u_p_avg_order_number', 'u_p_order_ratio', 'u_p_max_order_number',\n",
    "            'u_p_min_order_number',           \n",
    "            # ratios\n",
    "            'ratio_dspo', \n",
    "            # differences\n",
    "            'diff_order_dow', 'diff_order_hod', 'o_dspo_diff', 'u_p_time_since_last_buy', \n",
    "            'u_p_time_since_first_buy',\n",
    "            # categoricals\n",
    "            'max_dspo_order',  'u_p_in_last_order', 'u_p_in_2nd_last_order', 'u_p_in_3rd_last_order', \n",
    "           ]\n",
    "\n",
    "clf = lgb.LGBMClassifier(\n",
    "    task = 'train',\n",
    "    boosting_type = 'dart', # tried: [gbdt, dart, goss] \n",
    "    objective = 'binary',\n",
    "    metric = {'binary_logloss'},\n",
    "    num_leaves = 256, # tried: [40, 60, 80, 100, 128, 192, 225, 240, 256, 270, 300]\n",
    "    learning_rate = 0.55, # tried: [0.02, 0.05, 0.1, 0.2, 0.3, 0.5, 0.52, 0.54, 0.55, 0.56, 0.6, 0.7] (seems very high!)\n",
    "    min_data_in_leaf = 25, # tried: [10, 20, 22, 24, 25, 26, 27, 30]\n",
    "    )\n",
    "\n",
    "\n",
    "custom_folds = GroupKFold(n_splits=5).split(X=train[features], \n",
    "                                            y=train['reordered'], \n",
    "                                            groups=train['user_id'])\n",
    "\n",
    "\n",
    "cross_val_score(clf, \n",
    "                X=train[features], \n",
    "                y=train['reordered'],\n",
    "                scoring='neg_log_loss',\n",
    "                cv=custom_folds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "array([-0.24477021, -0.24627809, -0.24580046, -0.2452874 , -0.24366409])\n",
    "(Outputcheck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######################################################\n",
    "#\n",
    "# Final training of model!\n",
    "#\n",
    "######################################################\n",
    "\n",
    "train_lgb = lgb.Dataset(train[features], list(train['reordered'].values))\n",
    "res = lgb.train(params, train_lgb, 2000)\n",
    "\n",
    "\n",
    "test_cpy = test.copy()\n",
    "test_cpy['preds'] = res.predict(test_cpy[features])\n",
    "test_cpy = test_cpy[['order_id', 'user_id','product_id','preds']]\n",
    "\n",
    "test_cpy = test_cpy.sort_values(by='preds', ascending=False)\n",
    "test_cpy['prod_prob'] = zip(test_cpy['product_id'], test_cpy['preds'])\n",
    "prod_probs_by_order = test_cpy.groupby('order_id')['prod_prob'].aggregate(lambda x: list(x)).reset_index()\n",
    "prod_probs_by_order.columns = ['order_id','prod_probs']\n",
    "\n",
    "#this takes a long time, but does the job - @TODO: get rid of for loop\n",
    "final_pred = {}\n",
    "for order_id in prod_probs_by_order['order_id']:\n",
    "    pred_prods = []\n",
    "    unzipped = zip(*prod_probs_by_order[prod_probs_by_order['order_id'] == order_id]['prod_probs'].values[0])\n",
    "    k, none_in, exp = f1opt.maximize_expectation(unzipped[1])       \n",
    "    pred_prods.extend(unzipped[0][:k])\n",
    "    if (none_in) or (k == 0):\n",
    "        pred_prods.append('None')  \n",
    "    final_pred[order_id] = pred_prods\n",
    "    \n",
    "\n",
    "f_pred = collections.OrderedDict(sorted(final_pred.items()))\n",
    "sample_sub['order_id'] = f_pred.keys()\n",
    "sample_sub['products'] = f_pred.values()\n",
    "sample_sub['products'] = sample_sub['products'].apply(lambda x: (\" \".join(str(y) for y in x)))\n",
    "sample_sub.to_csv('submission_all_features_params_own.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally: some notes on applying model stacking in this competition\n",
    "\n",
    "The final boost on the Kaggle LB was obtained by stacking this model with results obtained by using XGBoost and RandomForest classifiers. The stacking method was a simple median selection, i.e., the probability fed into the f1 optimizer for selecting an item was the median probability retrieved from the output of the three models. This helped in catching some misclassifications.\n",
    "\n",
    "Stacking did not have a large impact. The boost for the final solution was from 0.397 to 0.403 (i.e., a boost of 0.006). This lifted this solution to within ~1% of the winning solution.\n",
    "\n",
    "Note however that the trade-off of introducing a training cost of more than 3x (XGBoost and particularly RandomForest are much more computationally expensive than LightGBM) versus a marginal predictive gain is probably not worth the effort, should we use our system in practice. It is therefore left out of this document."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3]",
   "language": "python",
   "name": "conda-env-python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
